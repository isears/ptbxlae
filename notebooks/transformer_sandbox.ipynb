{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.4597e-01, -1.6788e+00,  9.2153e-01,  ..., -1.2437e+00,\n",
       "          -6.9749e-01, -1.6794e-01],\n",
       "         [-6.7359e-01, -2.2914e-01, -1.2921e+00,  ..., -9.3115e-01,\n",
       "          -6.1806e-01, -7.6287e-01],\n",
       "         [-1.3457e+00, -1.5119e+00, -7.9694e-01,  ..., -2.9617e-01,\n",
       "           1.0630e+00, -2.0472e-01],\n",
       "         ...,\n",
       "         [ 3.5520e-01, -1.7880e+00,  1.4056e+00,  ..., -3.4810e-01,\n",
       "          -9.4158e-01, -1.9443e+00],\n",
       "         [-1.5999e+00, -7.8474e-01, -3.1210e-01,  ..., -5.3461e-01,\n",
       "          -2.6951e-02, -4.1283e-02],\n",
       "         [ 1.3329e+00,  1.5388e-01,  3.1111e-01,  ..., -1.0394e+00,\n",
       "           1.4376e+00, -9.6497e-03]],\n",
       "\n",
       "        [[ 3.6956e-01, -1.4428e+00, -2.4469e-01,  ...,  1.5894e+00,\n",
       "           5.3863e-01,  7.4549e-01],\n",
       "         [ 7.4659e-01, -7.4573e-01,  1.1308e+00,  ...,  4.7326e-01,\n",
       "          -1.2600e-03, -6.9762e-01],\n",
       "         [ 9.6777e-01,  4.5271e-01,  1.1527e+00,  ...,  2.0300e+00,\n",
       "          -6.4513e-01,  6.2160e-01],\n",
       "         ...,\n",
       "         [-2.4653e-01,  8.6698e-01,  1.4889e+00,  ...,  1.7415e-01,\n",
       "          -2.5400e-01, -8.4880e-01],\n",
       "         [-6.1097e-01,  9.1144e-01, -7.5677e-01,  ..., -1.5449e+00,\n",
       "          -4.6694e-01,  2.0106e+00],\n",
       "         [-4.9772e-01, -1.7351e+00, -1.0994e+00,  ..., -9.3366e-01,\n",
       "           1.3869e+00,  1.3223e+00]],\n",
       "\n",
       "        [[ 1.7085e+00,  1.3399e+00, -5.1845e-01,  ...,  1.4660e+00,\n",
       "          -5.3782e-01,  6.7268e-02],\n",
       "         [-2.0512e-01,  2.0223e+00, -4.4673e-01,  ..., -2.7214e-01,\n",
       "           8.0913e-01, -1.1691e+00],\n",
       "         [ 7.3850e-01,  1.3115e+00, -6.2174e-01,  ..., -7.9740e-01,\n",
       "          -4.8618e-01,  2.6293e+00],\n",
       "         ...,\n",
       "         [ 1.3132e+00,  2.6494e-01, -6.3729e-01,  ..., -4.0615e-01,\n",
       "          -9.5787e-02,  6.2265e-01],\n",
       "         [ 3.7616e-02, -1.3478e+00, -9.3807e-01,  ...,  8.0539e-01,\n",
       "           5.2156e-01,  1.9080e+00],\n",
       "         [ 1.1764e+00, -3.5934e-02,  8.8440e-01,  ...,  1.6630e+00,\n",
       "           6.6861e-01,  2.1806e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.2254e-01, -5.9754e-01,  1.3666e+00,  ...,  8.2663e-01,\n",
       "          -1.8161e-01,  4.0913e-02],\n",
       "         [-2.0656e-01, -7.2820e-02, -1.8893e-01,  ..., -9.9596e-02,\n",
       "          -5.0606e-01, -2.2104e+00],\n",
       "         [-3.4076e-01,  9.5643e-01, -3.3661e+00,  ..., -8.3819e-02,\n",
       "           2.5297e+00,  1.9400e+00],\n",
       "         ...,\n",
       "         [-4.2172e-01, -3.6195e-01,  7.5171e-01,  ..., -3.8795e-01,\n",
       "           3.5762e-01,  1.1411e+00],\n",
       "         [ 1.0762e+00,  3.1809e-01,  8.3054e-01,  ...,  8.1015e-01,\n",
       "           1.1357e+00, -1.4123e+00],\n",
       "         [-5.9999e-01,  2.1021e-01,  2.1675e-01,  ..., -1.2812e+00,\n",
       "           1.8560e+00,  3.7630e-01]],\n",
       "\n",
       "        [[ 9.6001e-01,  1.3291e-01, -1.8502e-02,  ...,  9.2555e-01,\n",
       "          -1.8425e+00,  1.9467e-01],\n",
       "         [ 2.6145e-01, -6.2265e-01, -2.7432e-01,  ...,  4.2045e-01,\n",
       "          -1.0642e+00,  5.5810e-01],\n",
       "         [ 1.2205e+00,  8.5802e-02,  2.6446e-01,  ..., -1.3349e+00,\n",
       "          -5.7573e-01,  2.7993e-01],\n",
       "         ...,\n",
       "         [ 3.3577e-01,  1.5158e+00, -4.9669e-01,  ...,  8.2743e-01,\n",
       "           5.1467e-01,  1.7535e+00],\n",
       "         [-1.6961e-01, -2.0851e-01, -2.0822e-01,  ..., -3.0226e-01,\n",
       "           2.0685e+00,  1.2333e-02],\n",
       "         [-6.8330e-01, -6.5203e-01,  7.4978e-01,  ...,  1.4948e+00,\n",
       "           1.4270e+00,  9.9609e-01]],\n",
       "\n",
       "        [[ 2.1901e-01, -5.1775e-01, -1.1781e+00,  ..., -1.4788e+00,\n",
       "           8.6015e-01,  1.0002e+00],\n",
       "         [-1.2869e+00, -4.9333e-01,  9.6571e-01,  ...,  1.4930e+00,\n",
       "           4.0692e-01, -5.7973e-01],\n",
       "         [ 4.0820e-01, -5.1846e-02,  2.4073e-01,  ...,  3.8870e-01,\n",
       "          -1.8606e+00, -5.3956e-01],\n",
       "         ...,\n",
       "         [ 5.2860e-01,  6.2381e-01,  5.9934e-01,  ..., -7.6389e-02,\n",
       "          -9.6615e-01, -4.0846e-01],\n",
       "         [-1.9031e-01,  9.0934e-01, -6.7100e-01,  ...,  2.0549e+00,\n",
       "          -7.9212e-01, -1.4822e+00],\n",
       "         [ 1.2334e+00,  4.2016e-01, -1.1074e-01,  ..., -1.9515e+00,\n",
       "           7.9038e-01, -8.6468e-01]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = torch.randn((16, 12, 1000))\n",
    "sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "embed_dim must be divisible by num_heads",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_encoder_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_decoder_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_feedforward\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m m\n",
      "File \u001b[0;32m~/VirtualEnvironments/dl/lib/python3.12/site-packages/torch/nn/modules/transformer.py:124\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, activation, custom_encoder, custom_decoder, layer_norm_eps, batch_first, norm_first, bias, device, dtype)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m custom_encoder\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m     encoder_layer \u001b[38;5;241m=\u001b[39m \u001b[43mTransformerEncoderLayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdim_feedforward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_norm_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     encoder_norm \u001b[38;5;241m=\u001b[39m LayerNorm(\n\u001b[1;32m    137\u001b[0m         d_model, eps\u001b[38;5;241m=\u001b[39mlayer_norm_eps, bias\u001b[38;5;241m=\u001b[39mbias, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs\n\u001b[1;32m    138\u001b[0m     )\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m TransformerEncoder(\n\u001b[1;32m    140\u001b[0m         encoder_layer, num_encoder_layers, encoder_norm\n\u001b[1;32m    141\u001b[0m     )\n",
      "File \u001b[0;32m~/VirtualEnvironments/dl/lib/python3.12/site-packages/torch/nn/modules/transformer.py:712\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.__init__\u001b[0;34m(self, d_model, nhead, dim_feedforward, dropout, activation, layer_norm_eps, batch_first, norm_first, bias, device, dtype)\u001b[0m\n\u001b[1;32m    710\u001b[0m factory_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m: device, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: dtype}\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m \u001b[43mMultiheadAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# Implementation of Feedforward model\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1 \u001b[38;5;241m=\u001b[39m Linear(d_model, dim_feedforward, bias\u001b[38;5;241m=\u001b[39mbias, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n",
      "File \u001b[0;32m~/VirtualEnvironments/dl/lib/python3.12/site-packages/torch/nn/modules/activation.py:1071\u001b[0m, in \u001b[0;36mMultiheadAttention.__init__\u001b[0;34m(self, embed_dim, num_heads, dropout, bias, add_bias_kv, add_zero_attn, kdim, vdim, batch_first, device, dtype)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;241m=\u001b[39m batch_first\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim \u001b[38;5;241m=\u001b[39m embed_dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_heads\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m-> 1071\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim \u001b[38;5;241m*\u001b[39m num_heads \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim\n\u001b[1;32m   1072\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membed_dim must be divisible by num_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qkv_same_embed_dim:\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj_weight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m   1076\u001b[0m         torch\u001b[38;5;241m.\u001b[39mempty((embed_dim, embed_dim), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n\u001b[1;32m   1077\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: embed_dim must be divisible by num_heads"
     ]
    }
   ],
   "source": [
    "m = torch.nn.Transformer(\n",
    "    d_model=512,\n",
    "    nhead=8,\n",
    "    num_encoder_layers=6,\n",
    "    num_decoder_layers=6,\n",
    "    dim_feedforward=2048,\n",
    "    batch_first=True\n",
    ")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "the feature number of src and tgt must be equal to d_model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m out\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/VirtualEnvironments/dl/lib/python3.12/site-packages/torch/nn/modules/transformer.py:268\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe batch number of src and tgt must be equal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;129;01mor\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model:\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     )\n\u001b[1;32m    272\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    273\u001b[0m     src,\n\u001b[1;32m    274\u001b[0m     mask\u001b[38;5;241m=\u001b[39msrc_mask,\n\u001b[1;32m    275\u001b[0m     src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask,\n\u001b[1;32m    276\u001b[0m     is_causal\u001b[38;5;241m=\u001b[39msrc_is_causal,\n\u001b[1;32m    277\u001b[0m )\n\u001b[1;32m    278\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[1;32m    279\u001b[0m     tgt,\n\u001b[1;32m    280\u001b[0m     memory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     memory_is_causal\u001b[38;5;241m=\u001b[39mmemory_is_causal,\n\u001b[1;32m    287\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: the feature number of src and tgt must be equal to d_model"
     ]
    }
   ],
   "source": [
    "out = m.forward(src=sample_batch, tgt=sample_batch)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
