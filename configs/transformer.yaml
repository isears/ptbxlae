model:
  class_path: ptbxlae.modeling.maskedPretrainingTransformer.MaskedPretrainingTransformer
  init_args:
    lr: 1e-4
    d_model: 64
    max_len: 1000
    nhead: 4
    nlayers: 3
    embedding_kernel: 7

data:
  class_path: ptbxlae.dataprocessing.dataModules.DefaultDM
  init_args:
    batch_size: 32
    ds:
      class_path: ptbxlae.dataprocessing.maskingDS.MixedSegmentMaskingDS
      init_args:
        mask_proportion: 0.5
        unmasked_ekg_dataset:
          class_path: ptbxlae.dataprocessing.mimicDS.MimicDS
        